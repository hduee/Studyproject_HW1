{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T13:13:57.889461Z",
     "start_time": "2025-11-10T13:13:57.886996Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from cmdstanpy import CmdStanModel\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Bayesian Cognitive and Rational Speech Act models\n",
    "\n",
    "This homework assignment is to be completed in groups. It is due on November 27, 2025 (midnight). Please upload *all files you created or modified* to the homework folder of your group in studIP.\n",
    "\n",
    "Group number:\n",
    "\n",
    "Names:\n",
    "\n",
    "*General note: It is permitted to use AI tools for coding. Please refer to the uploaded manual `AI_Tools_Guidelines` for recommended ways how to use AI to advance your studies in a way that supports your learning. That means that you should not be satisfied if an AI tool hands you a working version of your code, but that you should put in effort to understand how exactly the problem is solved. Another note of caution: What might work for large programming languages like Python, does not necessarily work for Stan. Check your code carefully and do NOT blindly trust AI.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "During the past weeks, you have learned how Bayesian inference works and how it can be used in Bayesian cognitive models. You also learned about a specific type of Bayesian models that can be used to model pragmatic language understanding and production, the Rational Speech Act models. The goal of this homework assignment is for you to learn how to implement Bayesian models in Stan and, specifically, how to implement RSA models in Stan. A special focus will be on the different use cases and evaluation methods of RSA models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Stan modeling (8 points)\n",
    "\n",
    "1.1) In the file `simple_model.stan`, you will find a simple Stan model. Describe its implementation, relating it to the knowledge you gained about the conventions for coding models in Stan. (4 points)\n",
    "\n",
    "1.2) You will notice that the model does not compile. Fix the problems and explain what you did. (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Bayesian cognitive models (10 points)\n",
    "Think of a use case for `simple_model.stan` in the scope of Bayesian cognitive modeling. Describe the model while answering the following questions:\n",
    "\n",
    "2.1) What cognitive capacity can be explained by this model? (2 points) \n",
    "\n",
    "2.2) What is the purpose and function of this model? (3 points)\n",
    "\n",
    "2.3) At which level of analysis does it model this cognitive capacity and why? (3 points)\n",
    "\n",
    "Overall coherence gives another 2 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) RSA modeling (82 points)\n",
    "The purpose of the following model is to explain the use of overinformative referring expressions in pragmatic communication. In referential communication, the speaker’s task is to produce a referring expression that allows a listener to identify the target in the context. Consider the context below, where the target is the small blue pin. A referring expression including a size adjective (the small pin) is strictly speaking sufficient for uniquely establishing reference to the target, yet speakers often “overmodify” with color, producing referring expressions like the small blue pin. This overmodification phenomenon is what the model is intended to capture.\n",
    "\n",
    "<img src=\"img/size-sufficient.png\" width=\"400\"/>\n",
    "\n",
    "### 3.1) Vanilla RSA (20 points)\n",
    "In the file `vanilla_rsa.stan`, you find an RSA model of the production of referring expressions, based on the vanilla RSA model of Frank & Goodman (2012) that we discussed in class.\n",
    "\n",
    "3.1.1) Provide informative comments in the file `vanilla_rsa.stan`. (4 points)\n",
    "\n",
    "3.1.2) You will notice that the parameters and model blocks are empty. Why is that? Go through the following code and inspect the model's behavior. Look at the stan variables that are included in the fitted model. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:58:12.006198Z",
     "start_time": "2025-11-11T09:58:11.938342Z"
    }
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "stan_file = os.path.join('stan', 'vanilla_rsa.stan')\n",
    "rsa_model = CmdStanModel(stan_file=stan_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T13:16:47.445896Z",
     "start_time": "2025-11-10T13:16:47.442173Z"
    }
   },
   "outputs": [],
   "source": [
    "# define input data\n",
    "states = [\"big_blue\", \"big_red\", \"small_blue\"]\n",
    "utterances = [\n",
    "    \"big\", \"small\", \"blue\", \"red\"\n",
    "]\n",
    "n_states = len(states)\n",
    "n_utterances   = len(utterances)\n",
    "\n",
    "# build meaning_matrix[u, s]\n",
    "meaning_matrix = np.zeros((n_utterances, n_states), dtype=int)\n",
    "for u, utterance in enumerate(utterances):\n",
    "    for s, state in enumerate(states):\n",
    "        # literal meaning maps to true iff the utterance string appears in the state string\n",
    "        # Stan cannot handle booleans, so we need to work with integers here\n",
    "        meaning_matrix[u, s] = int(utterance in state)\n",
    "\n",
    "# parameters - change them here\n",
    "alpha = 1.0\n",
    "cost_weight = 1.0\n",
    "\n",
    "# cost function\n",
    "cost_dict = {\n",
    "    \"big\": 0.0,\n",
    "    \"small\": 0.0,\n",
    "    \"blue\": 0.0,\n",
    "    \"red\": 0.0,\n",
    "}\n",
    "cost = np.array([cost_dict[utterance] for utterance in utterances])\n",
    "\n",
    "# prepare Stan data as dictionary\n",
    "stan_data = {\n",
    "    \"S\": n_states,\n",
    "    \"U\": n_utterances,\n",
    "    \"meaning_matrix\": meaning_matrix.tolist(), # Stan cannot handle numpy arrays       \n",
    "    \"cost\": cost.tolist(),                     # or dictionaries\n",
    "    \"alpha\": alpha,\n",
    "    \"cost_weight\": cost_weight\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:40:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:40:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [1] method = sample (Default)\n",
      "Chain [1] sample\n",
      "Chain [1] num_samples = 1\n",
      "Chain [1] num_warmup = 0\n",
      "Chain [1] save_warmup = 0 (Default)\n",
      "Chain [1] thin = 1 (Default)\n",
      "Chain [1] adapt\n",
      "Chain [1] engaged = 0\n",
      "Chain [1] gamma = 0.050000000000000003 (Default)\n",
      "Chain [1] delta = 0.80000000000000004 (Default)\n",
      "Chain [1] kappa = 0.75 (Default)\n",
      "Chain [1] t0 = 10 (Default)\n",
      "Chain [1] init_buffer = 75 (Default)\n",
      "Chain [1] term_buffer = 50 (Default)\n",
      "Chain [1] window = 25 (Default)\n",
      "Chain [1] algorithm = hmc (Default)\n",
      "Chain [1] hmc\n",
      "Chain [1] engine = nuts (Default)\n",
      "Chain [1] nuts\n",
      "Chain [1] max_depth = 10 (Default)\n",
      "Chain [1] metric = diag_e (Default)\n",
      "Chain [1] metric_file =  (Default)\n",
      "Chain [1] stepsize = 1 (Default)\n",
      "Chain [1] stepsize_jitter = 0 (Default)\n",
      "Chain [1] num_chains = 1 (Default)\n",
      "Chain [1] id = 1 (Default)\n",
      "Chain [1] data\n",
      "Chain [1] file = C:\\Users\\Hannes\\AppData\\Local\\Temp\\tmps90uo67g\\vm7n8blt.json\n",
      "Chain [1] init = 2 (Default)\n",
      "Chain [1] random\n",
      "Chain [1] seed = 69658\n",
      "Chain [1] output\n",
      "Chain [1] file = C:\\Users\\Hannes\\AppData\\Local\\Temp\\tmps90uo67g\\vanilla_rsa1z2ra02t\\vanilla_rsa-20251121144008.csv\n",
      "Chain [1] diagnostic_file =  (Default)\n",
      "Chain [1] refresh = 100 (Default)\n",
      "Chain [1] sig_figs = -1 (Default)\n",
      "Chain [1] profile_file = profile.csv (Default)\n",
      "Chain [1] num_threads = 1 (Default)\n",
      "Chain [1] \n",
      "Chain [1] Model contains no parameters, running fixed_param sampler, no updates to Markov chain\n",
      "Chain [1] Iteration: 1 / 1 [100%]  (Sampling)\n",
      "Chain [1] \n",
      "Chain [1] Elapsed Time: 0 seconds (Warm-up)\n",
      "Chain [1] 0 seconds (Sampling)\n",
      "Chain [1] 0 seconds (Total)\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n"
     ]
    }
   ],
   "source": [
    "fit = rsa_model.sample(stan_data, show_console=True, chains=1, iter_warmup=0, adapt_engaged=False, iter_sampling=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.3) Are the outputs in line with what you would expect given your knowledge about pragmatic communication and overinformative referring expressions?\n",
    "Add complex utterances to the model (i.e., utterance consisting of a size and color adjective) and inspect the output again. The meaning of a complex two-word utterance is defined with intuitive intersective semantics: $$\\mathcal{L}(u_{\\text{complex}}, o)=\\mathcal{L}(u_{\\text{size}},o)\\times\\mathcal{L}(u_{\\text{color}},o)$$ (6 points)\n",
    "\n",
    "3.1.4) Play around with the rationality and cost weight parameters. How do they affect the model output? (4 points)\n",
    "\n",
    "3.1.5) Adapt the utterance cost in a way that achieves a preference for overinformative referring expressions. (2 points)\n",
    "\n",
    "3.1.6) Adapt the utterance cost in a way that seems most natural to you. (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Relaxed semantics (20 points)\n",
    "It seems that our intuitions do not align well with the model. Let's use continuous rather than boolean semantics to see whether this can solve our problem. In the following, you need to adapt the RSA model and input data in a way that implements continuous semantics. The only change will be that the lexicon, or meaning matrix, should return real values instead of true or false: $$\\mathcal{L}(u,o)\\in [0,1] \\subset \\mathbb{R}$$\n",
    "This approach captures the intuition that an object is not unambiguously big or blue, but rather that objects can count as big or blue to varying degrees.\n",
    "\n",
    "3.2.1) Build a meaning matrix that captures the relaxed semantics with two new parameters size_semantics $x_\\text{size}$ and color_semantics $x_\\text{color}$. When an object $o$ is in the extension of a size adjective under the Boolean semantics defined above, take $\\mathcal{L}(u,o)=x_\\text{size}$, else $\\mathcal{L}(u,o)=1-x_\\text{size}$. The semantics are defined analogously for color. (6 points)\n",
    "\n",
    "3.2.2) Run the model with alpha = 30, size_semantics = 0.8 and color_semantics = 0.99. Inspect the model outputs. (4 points)\n",
    "\n",
    "3.2.3) Visualize the results of varying values for size_semantics and color_semantics, pit them against each other and interpret them. (6 points)\n",
    "\n",
    "3.2.4) Van Gompel et al. (2019) found that speakers use overinformative referring expressions in about 80% of the trials that look like the one above, where size is sufficient to mention. What about contexts where color is sufficient to mention? Construct a context where color is sufficient to mention and interpret the output. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "stan_file = os.path.join('stan', 'vanilla_rsa_relaxed_semantics.stan')\n",
    "rsa_model = CmdStanModel(stan_file=stan_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the code for exercise 3.2, adapted from the code for exercise 3.1.\n",
    "\n",
    "# maybe create a new Stan file vanilla_rsa_relaxed_semantics.stan with the following change compared to vanilla_rsa.stan:\n",
    "# parameters {\n",
    "#  real<lower=0,upper=1> x_size;\n",
    "#  real<lower=0,upper=1> x_color;\n",
    "#}\n",
    "\n",
    "# fixed parameters\n",
    "x_size = 0.8     \n",
    "x_color = 0.2    \n",
    "\n",
    "# define input data\n",
    "states = [\"big_blue\", \"big_red\", \"small_blue\"]\n",
    "utterances = [\n",
    "    \"big\", \"small\", \"blue\", \"red\"\n",
    "]\n",
    "n_states = len(states)\n",
    "n_utterances   = len(utterances)\n",
    "\n",
    "# introduce size/color categorization\n",
    "size_utterances  = [\"big\", \"small\"]\n",
    "color_utterances = [\"blue\", \"red\"]\n",
    "\n",
    "# build meaning_matrix[u, s]\n",
    "meaning_matrix = np.zeros((n_utterances, n_states))\n",
    "for u, utterance in enumerate(utterances):\n",
    "    for s, state in enumerate(states):\n",
    "        # check if object is in the extension of an adjective under Boolean semantics\n",
    "        extension = utterance in state\n",
    "        # check utterance category\n",
    "        if utterance in size_utterances:\n",
    "            x = x_size\n",
    "        elif utterance in color_utterances:\n",
    "            x = x_color\n",
    "        # if object is in the extension of an adjective, take L(u,o) = x_size/color, else L(u,o) = 1 - x_size/color\n",
    "        meaning_matrix[u, s] = x if extension else (1 - x)\n",
    "\n",
    "# parameters - change them here\n",
    "alpha = 30\n",
    "cost_weight = 1.0\n",
    "\n",
    "# cost function\n",
    "cost_dict = {\n",
    "    \"big\": 0.0,\n",
    "    \"small\": 0.0,\n",
    "    \"blue\": 0.0,\n",
    "    \"red\": 0.0,\n",
    "}\n",
    "cost = np.array([cost_dict[utterance] for utterance in utterances])\n",
    "\n",
    "# prepare Stan data as dictionary\n",
    "stan_data = {\n",
    "    \"S\": n_states,\n",
    "    \"U\": n_utterances,\n",
    "    \"meaning_matrix\": meaning_matrix.tolist(), # Stan cannot handle numpy arrays       \n",
    "    \"cost\": cost.tolist(),                     # or dictionaries\n",
    "    \"alpha\": alpha,\n",
    "    \"cost_weight\": cost_weight,\n",
    "    \"x_size\": x_size,\n",
    "    \"x_color\": x_color\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:39:51 - cmdstanpy - INFO - Chain [2] start processing\n",
      "11:39:51 - cmdstanpy - INFO - Chain [3] start processing\n",
      "11:39:51 - cmdstanpy - INFO - Chain [4] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [1] method = sample (Default)\n",
      "Chain [1] sample\n",
      "Chain [1] num_samples = 500\n",
      "Chain [1] num_warmup = 500\n",
      "Chain [1] save_warmup = 0 (Default)\n",
      "Chain [1] thin = 1 (Default)\n",
      "Chain [1] adapt\n",
      "Chain [1] engaged = 1 (Default)\n",
      "Chain [1] gamma = 0.050000000000000003 (Default)\n",
      "Chain [1] delta = 0.80000000000000004 (Default)\n",
      "Chain [1] kappa = 0.75 (Default)\n",
      "Chain [1] t0 = 10 (Default)\n",
      "Chain [1] init_buffer = 75 (Default)\n",
      "Chain [1] term_buffer = 50 (Default)\n",
      "Chain [1] window = 25 (Default)\n",
      "Chain [1] algorithm = hmc (Default)\n",
      "Chain [1] hmc\n",
      "Chain [1] engine = nuts (Default)\n",
      "Chain [1] nuts\n",
      "Chain [1] max_depth = 10 (Default)\n",
      "Chain [1] metric = diag_e (Default)\n",
      "Chain [1] metric_file =  (Default)\n",
      "Chain [1] stepsize = 1 (Default)\n",
      "Chain [1] stepsize_jitter = 0 (Default)\n",
      "Chain [1] num_chains = 1 (Default)\n",
      "Chain [1] id = 1 (Default)\n",
      "Chain [1] data\n",
      "Chain [1] file = C:\\Users\\Hannes\\AppData\\Local\\Temp\\tmpkpubl3oz\\dulr_wl8.json\n",
      "Chain [1] init = 2 (Default)\n",
      "Chain [1] random\n",
      "Chain [1] seed = 84947\n",
      "Chain [1] output\n",
      "Chain [1] file = C:\\Users\\Hannes\\AppData\\Local\\Temp\\tmpkpubl3oz\\vanilla_rsa_relaxed_semanticsf4z2mlnh\\vanilla_rsa_relaxed_semantics-20251125113951_1.csv\n",
      "Chain [1] diagnostic_file =  (Default)\n",
      "Chain [1] refresh = 100 (Default)\n",
      "Chain [1] sig_figs = -1 (Default)\n",
      "Chain [1] profile_file = profile.csv (Default)\n",
      "Chain [1] num_threads = 1 (Default)\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] Gradient evaluation took 6.3e-005 seconds\n",
      "Chain [1] 1000 transitions using 10 leapfrog steps per transition would take 0.63 seconds.\n",
      "Chain [1] Adjust your expectations accordingly!\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain [1] Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain [1] Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain [1] Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain [4] method = sample (Default)\n",
      "Chain [4] sample\n",
      "Chain [4] num_samples = 500\n",
      "Chain [4] num_warmup = 500\n",
      "Chain [4] save_warmup = 0 (Default)\n",
      "Chain [4] thin = 1 (Default)\n",
      "Chain [4] adapt\n",
      "Chain [4] engaged = 1 (Default)\n",
      "Chain [4] gamma = 0.050000000000000003 (Default)\n",
      "Chain [4] delta = 0.80000000000000004 (Default)\n",
      "Chain [4] kappa = 0.75 (Default)\n",
      "Chain [4] t0 = 10 (Default)\n",
      "Chain [4] init_buffer = 75 (Default)\n",
      "Chain [4] term_buffer = 50 (Default)\n",
      "Chain [4] window = 25 (Default)\n",
      "Chain [4] algorithm = hmc (Default)\n",
      "Chain [4] hmc\n",
      "Chain [4] engine = nuts (Default)\n",
      "Chain [4] nuts\n",
      "Chain [4] max_depth = 10 (Default)\n",
      "Chain [4] metric = diag_e (Default)\n",
      "Chain [4] metric_file =  (Default)\n",
      "Chain [4] stepsize = 1 (Default)\n",
      "Chain [4] stepsize_jitter = 0 (Default)\n",
      "Chain [4] num_chains = 1 (Default)\n",
      "Chain [4] id = 4\n",
      "Chain [4] data\n",
      "Chain [4] file = C:\\Users\\Hannes\\AppData\\Local\\Temp\\tmpkpubl3oz\\dulr_wl8.json\n",
      "Chain [4] init = 2 (Default)\n",
      "Chain [4] random\n",
      "Chain [4] seed = 84947\n",
      "Chain [4] output\n",
      "Chain [4] file = C:\\Users\\Hannes\\AppData\\Local\\Temp\\tmpkpubl3oz\\vanilla_rsa_relaxed_semanticsf4z2mlnh\\vanilla_rsa_relaxed_semantics-20251125113951_4.csv\n",
      "Chain [4] diagnostic_file =  (Default)\n",
      "Chain [4] refresh = 100 (Default)\n",
      "Chain [4] sig_figs = -1 (Default)\n",
      "Chain [4] profile_file = profile.csv (Default)\n",
      "Chain [4] num_threads = 1 (Default)\n",
      "Chain [4] \n",
      "Chain [3] method = sample (Default)\n",
      "Chain [3] sample\n",
      "Chain [3] num_samples = 500\n",
      "Chain [3] num_warmup = 500\n",
      "Chain [3] save_warmup = 0 (Default)\n",
      "Chain [3] thin = 1 (Default)\n",
      "Chain [3] adapt\n",
      "Chain [3] engaged = 1 (Default)\n",
      "Chain [3] gamma = 0.050000000000000003 (Default)\n",
      "Chain [3] delta = 0.80000000000000004 (Default)\n",
      "Chain [3] kappa = 0.75 (Default)\n",
      "Chain [3] t0 = 10 (Default)\n",
      "Chain [3] init_buffer = 75 (Default)\n",
      "Chain [3] term_buffer = 50 (Default)\n",
      "Chain [3] window = 25 (Default)\n",
      "Chain [3] algorithm = hmc (Default)\n",
      "Chain [3] hmc\n",
      "Chain [3] engine = nuts (Default)\n",
      "Chain [3] nuts\n",
      "Chain [3] max_depth = 10 (Default)\n",
      "Chain [3] metric = diag_e (Default)\n",
      "Chain [3] metric_file =  (Default)\n",
      "Chain [3] stepsize = 1 (Default)\n",
      "Chain [3] stepsize_jitter = 0 (Default)\n",
      "Chain [3] num_chains = 1 (Default)\n",
      "Chain [3] id = 3\n",
      "Chain [3] data\n",
      "Chain [3] file = C:\\Users\\Hannes\\AppData\\Local\\Temp\\tmpkpubl3oz\\dulr_wl8.json\n",
      "Chain [3] init = 2 (Default)\n",
      "Chain [3] random\n",
      "Chain [3] seed = 84947\n",
      "Chain [3] output\n",
      "Chain [3] file = C:\\Users\\Hannes\\AppData\\Local\\Temp\\tmpkpubl3oz\\vanilla_rsa_relaxed_semanticsf4z2mlnh\\vanilla_rsa_relaxed_semantics-20251125113951_3.csv\n",
      "Chain [3] diagnostic_file =  (Default)\n",
      "Chain [3] refresh = 100 (Default)\n",
      "Chain [3] sig_figs = -1 (Default)\n",
      "Chain [3] profile_file = profile.csv (Default)\n",
      "Chain [3] num_threads = 1 (Default)\n",
      "Chain [3] \n",
      "Chain [1] Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain [1] Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain [1] Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain [2] method = sample (Default)\n",
      "Chain [2] sample\n",
      "Chain [2] num_samples = 500\n",
      "Chain [2] num_warmup = 500\n",
      "Chain [2] save_warmup = 0 (Default)\n",
      "Chain [2] thin = 1 (Default)\n",
      "Chain [2] adapt\n",
      "Chain [2] engaged = 1 (Default)\n",
      "Chain [2] gamma = 0.050000000000000003 (Default)\n",
      "Chain [2] delta = 0.80000000000000004 (Default)\n",
      "Chain [2] kappa = 0.75 (Default)\n",
      "Chain [2] t0 = 10 (Default)\n",
      "Chain [2] init_buffer = 75 (Default)\n",
      "Chain [2] term_buffer = 50 (Default)\n",
      "Chain [2] window = 25 (Default)\n",
      "Chain [2] algorithm = hmc (Default)\n",
      "Chain [2] hmc\n",
      "Chain [2] engine = nuts (Default)\n",
      "Chain [2] nuts\n",
      "Chain [2] max_depth = 10 (Default)\n",
      "Chain [2] metric = diag_e (Default)\n",
      "Chain [2] metric_file =  (Default)\n",
      "Chain [2] stepsize = 1 (Default)\n",
      "Chain [2] stepsize_jitter = 0 (Default)\n",
      "Chain [2] num_chains = 1 (Default)\n",
      "Chain [2] id = 2\n",
      "Chain [2] data\n",
      "Chain [2] file = C:\\Users\\Hannes\\AppData\\Local\\Temp\\tmpkpubl3oz\\dulr_wl8.json\n",
      "Chain [2] init = 2 (Default)\n",
      "Chain [2] random\n",
      "Chain [2] seed = 84947\n",
      "Chain [2] output\n",
      "Chain [2] file = C:\\Users\\Hannes\\AppData\\Local\\Temp\\tmpkpubl3oz\\vanilla_rsa_relaxed_semanticsf4z2mlnh\\vanilla_rsa_relaxed_semantics-20251125113951_2.csv\n",
      "Chain [2] diagnostic_file =  (Default)\n",
      "Chain [2] refresh = 100 (Default)\n",
      "Chain [2] sig_figs = -1 (Default)\n",
      "Chain [2] profile_file = profile.csv (Default)\n",
      "Chain [2] num_threads = 1 (Default)\n",
      "Chain [2] \n",
      "Chain [1] Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain [1] Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain [1] Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain [1] Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain [1] Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain [1] \n",
      "Chain [1] Elapsed Time: 0.034 seconds (Warm-up)\n",
      "Chain [1] 0.061 seconds (Sampling)\n",
      "Chain [1] 0.095 seconds (Total)\n",
      "Chain [1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:39:51 - cmdstanpy - INFO - Chain [4] done processing\n",
      "11:39:51 - cmdstanpy - INFO - Chain [2] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [4] \n",
      "Chain [4] Gradient evaluation took 5.8e-005 seconds\n",
      "Chain [4] 1000 transitions using 10 leapfrog steps per transition would take 0.58 seconds.\n",
      "Chain [4] Adjust your expectations accordingly!\n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain [4] Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain [4] Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain [4] Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain [4] Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain [4] Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain [4] Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain [2] \n",
      "Chain [2] Gradient evaluation took 4.2e-005 seconds\n",
      "Chain [2] 1000 transitions using 10 leapfrog steps per transition would take 0.42 seconds.\n",
      "Chain [2] Adjust your expectations accordingly!\n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [3] \n",
      "Chain [3] Gradient evaluation took 0.000804 seconds\n",
      "Chain [3] 1000 transitions using 10 leapfrog steps per transition would take 8.04 seconds.\n",
      "Chain [3] Adjust your expectations accordingly!\n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain [2] Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain [3] Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain [4] Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain [2] Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain [3] Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain [2] Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain [4] Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain [3] Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain [2] Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain [3] Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain [2] Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain [2] Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain [3] Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain [4] Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain [3] Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain [2] Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain [3] Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain [4] Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain [2] Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain [4] Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain [4] \n",
      "Chain [3] Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain [4] Elapsed Time: 0.041 seconds (Warm-up)\n",
      "Chain [4] 0.087 seconds (Sampling)\n",
      "Chain [4] 0.128 seconds (Total)\n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [4] \n",
      "Chain [2] Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain [3] Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain [2] Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain [3] Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain [2] Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain [2] \n",
      "Chain [2] Elapsed Time: 0.029 seconds (Warm-up)\n",
      "Chain [2] 0.083 seconds (Sampling)\n",
      "Chain [2] 0.112 seconds (Total)\n",
      "Chain [2] \n",
      "Chain [3] Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain [3] \n",
      "Chain [3] Elapsed Time: 0.031 seconds (Warm-up)\n",
      "Chain [3] 0.08 seconds (Sampling)\n",
      "Chain [3] 0.111 seconds (Total)\n",
      "Chain [3] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n",
      "Chain [2] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:51 - cmdstanpy - INFO - Chain [3] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n",
      "Chain [3] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>MCSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>N_Eff</th>\n",
       "      <th>N_Eff/s</th>\n",
       "      <th>R_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lp__</th>\n",
       "      <td>-3.956620e+00</td>\n",
       "      <td>0.041909</td>\n",
       "      <td>1.137810e+00</td>\n",
       "      <td>-6.250050e+00</td>\n",
       "      <td>-3.609710e+00</td>\n",
       "      <td>-2.838280e+00</td>\n",
       "      <td>737.088</td>\n",
       "      <td>2370.06</td>\n",
       "      <td>1.007780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_size</th>\n",
       "      <td>4.910170e-01</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>2.806880e-01</td>\n",
       "      <td>5.430820e-02</td>\n",
       "      <td>4.869780e-01</td>\n",
       "      <td>9.371240e-01</td>\n",
       "      <td>1430.630</td>\n",
       "      <td>4600.08</td>\n",
       "      <td>0.999534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_color</th>\n",
       "      <td>4.946470e-01</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>2.875550e-01</td>\n",
       "      <td>4.664030e-02</td>\n",
       "      <td>4.946820e-01</td>\n",
       "      <td>9.559760e-01</td>\n",
       "      <td>1632.820</td>\n",
       "      <td>5250.24</td>\n",
       "      <td>1.003650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_prior[1]</th>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e-16</td>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_prior[2]</th>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e-16</td>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_prior[3]</th>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e-16</td>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>3.333330e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_prior[1]</th>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_prior[2]</th>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_prior[3]</th>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_prior[4]</th>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[1,1]</th>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.200000e-15</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[1,2]</th>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.200000e-15</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[1,3]</th>\n",
       "      <td>1.111110e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.111110e-01</td>\n",
       "      <td>1.111110e-01</td>\n",
       "      <td>1.111110e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[2,1]</th>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e-16</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[2,2]</th>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e-16</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[2,3]</th>\n",
       "      <td>6.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.400000e-15</td>\n",
       "      <td>6.666670e-01</td>\n",
       "      <td>6.666670e-01</td>\n",
       "      <td>6.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[3,1]</th>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e-16</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[3,2]</th>\n",
       "      <td>6.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.400000e-15</td>\n",
       "      <td>6.666670e-01</td>\n",
       "      <td>6.666670e-01</td>\n",
       "      <td>6.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[3,3]</th>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e-16</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>1.666670e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[4,1]</th>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.200000e-15</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[4,2]</th>\n",
       "      <td>1.111110e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>1.111110e-01</td>\n",
       "      <td>1.111110e-01</td>\n",
       "      <td>1.111110e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0[4,3]</th>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.200000e-15</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>4.444440e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[1,1]</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000e-16</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[1,2]</th>\n",
       "      <td>8.310000e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.310000e-14</td>\n",
       "      <td>8.310000e-14</td>\n",
       "      <td>8.310000e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[1,3]</th>\n",
       "      <td>8.310000e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.310000e-14</td>\n",
       "      <td>8.310000e-14</td>\n",
       "      <td>8.310000e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[1,4]</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000e-16</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[2,1]</th>\n",
       "      <td>5.215070e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.215070e-06</td>\n",
       "      <td>5.215070e-06</td>\n",
       "      <td>5.215070e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[2,2]</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[2,3]</th>\n",
       "      <td>9.999950e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050000e-14</td>\n",
       "      <td>9.999950e-01</td>\n",
       "      <td>9.999950e-01</td>\n",
       "      <td>9.999950e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[2,4]</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[3,1]</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[3,2]</th>\n",
       "      <td>9.999950e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050000e-14</td>\n",
       "      <td>9.999950e-01</td>\n",
       "      <td>9.999950e-01</td>\n",
       "      <td>9.999950e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[3,3]</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1[3,4]</th>\n",
       "      <td>5.215070e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.215070e-06</td>\n",
       "      <td>5.215070e-06</td>\n",
       "      <td>5.215070e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Mean      MCSE        StdDev            5%  \\\n",
       "lp__               -3.956620e+00  0.041909  1.137810e+00 -6.250050e+00   \n",
       "x_size              4.910170e-01  0.007421  2.806880e-01  5.430820e-02   \n",
       "x_color             4.946470e-01  0.007116  2.875550e-01  4.664030e-02   \n",
       "state_prior[1]      3.333330e-01       NaN  4.000000e-16  3.333330e-01   \n",
       "state_prior[2]      3.333330e-01       NaN  4.000000e-16  3.333330e-01   \n",
       "state_prior[3]      3.333330e-01       NaN  4.000000e-16  3.333330e-01   \n",
       "utterance_prior[1]  2.500000e-01       NaN  1.000000e-16  2.500000e-01   \n",
       "utterance_prior[2]  2.500000e-01       NaN  1.000000e-16  2.500000e-01   \n",
       "utterance_prior[3]  2.500000e-01       NaN  1.000000e-16  2.500000e-01   \n",
       "utterance_prior[4]  2.500000e-01       NaN  1.000000e-16  2.500000e-01   \n",
       "L0[1,1]             4.444440e-01       NaN  4.200000e-15  4.444440e-01   \n",
       "L0[1,2]             4.444440e-01       NaN  4.200000e-15  4.444440e-01   \n",
       "L0[1,3]             1.111110e-01       NaN  1.000000e-15  1.111110e-01   \n",
       "L0[2,1]             1.666670e-01       NaN  4.000000e-16  1.666670e-01   \n",
       "L0[2,2]             1.666670e-01       NaN  4.000000e-16  1.666670e-01   \n",
       "L0[2,3]             6.666670e-01       NaN  5.400000e-15  6.666670e-01   \n",
       "L0[3,1]             1.666670e-01       NaN  4.000000e-16  1.666670e-01   \n",
       "L0[3,2]             6.666670e-01       NaN  5.400000e-15  6.666670e-01   \n",
       "L0[3,3]             1.666670e-01       NaN  4.000000e-16  1.666670e-01   \n",
       "L0[4,1]             4.444440e-01       NaN  4.200000e-15  4.444440e-01   \n",
       "L0[4,2]             1.111110e-01       NaN  1.000000e-15  1.111110e-01   \n",
       "L0[4,3]             4.444440e-01       NaN  4.200000e-15  4.444440e-01   \n",
       "S1[1,1]             5.000000e-01       NaN  3.000000e-16  5.000000e-01   \n",
       "S1[1,2]             8.310000e-14       NaN  0.000000e+00  8.310000e-14   \n",
       "S1[1,3]             8.310000e-14       NaN  0.000000e+00  8.310000e-14   \n",
       "S1[1,4]             5.000000e-01       NaN  3.000000e-16  5.000000e-01   \n",
       "S1[2,1]             5.215070e-06       NaN  0.000000e+00  5.215070e-06   \n",
       "S1[2,2]             0.000000e+00       NaN  0.000000e+00  0.000000e+00   \n",
       "S1[2,3]             9.999950e-01       NaN  1.050000e-14  9.999950e-01   \n",
       "S1[2,4]             0.000000e+00       NaN  0.000000e+00  0.000000e+00   \n",
       "S1[3,1]             0.000000e+00       NaN  0.000000e+00  0.000000e+00   \n",
       "S1[3,2]             9.999950e-01       NaN  1.050000e-14  9.999950e-01   \n",
       "S1[3,3]             0.000000e+00       NaN  0.000000e+00  0.000000e+00   \n",
       "S1[3,4]             5.215070e-06       NaN  0.000000e+00  5.215070e-06   \n",
       "\n",
       "                             50%           95%     N_Eff  N_Eff/s     R_hat  \n",
       "lp__               -3.609710e+00 -2.838280e+00   737.088  2370.06  1.007780  \n",
       "x_size              4.869780e-01  9.371240e-01  1430.630  4600.08  0.999534  \n",
       "x_color             4.946820e-01  9.559760e-01  1632.820  5250.24  1.003650  \n",
       "state_prior[1]      3.333330e-01  3.333330e-01       NaN      NaN       NaN  \n",
       "state_prior[2]      3.333330e-01  3.333330e-01       NaN      NaN       NaN  \n",
       "state_prior[3]      3.333330e-01  3.333330e-01       NaN      NaN       NaN  \n",
       "utterance_prior[1]  2.500000e-01  2.500000e-01       NaN      NaN       NaN  \n",
       "utterance_prior[2]  2.500000e-01  2.500000e-01       NaN      NaN       NaN  \n",
       "utterance_prior[3]  2.500000e-01  2.500000e-01       NaN      NaN       NaN  \n",
       "utterance_prior[4]  2.500000e-01  2.500000e-01       NaN      NaN       NaN  \n",
       "L0[1,1]             4.444440e-01  4.444440e-01       NaN      NaN       NaN  \n",
       "L0[1,2]             4.444440e-01  4.444440e-01       NaN      NaN       NaN  \n",
       "L0[1,3]             1.111110e-01  1.111110e-01       NaN      NaN       NaN  \n",
       "L0[2,1]             1.666670e-01  1.666670e-01       NaN      NaN       NaN  \n",
       "L0[2,2]             1.666670e-01  1.666670e-01       NaN      NaN       NaN  \n",
       "L0[2,3]             6.666670e-01  6.666670e-01       NaN      NaN       NaN  \n",
       "L0[3,1]             1.666670e-01  1.666670e-01       NaN      NaN       NaN  \n",
       "L0[3,2]             6.666670e-01  6.666670e-01       NaN      NaN       NaN  \n",
       "L0[3,3]             1.666670e-01  1.666670e-01       NaN      NaN       NaN  \n",
       "L0[4,1]             4.444440e-01  4.444440e-01       NaN      NaN       NaN  \n",
       "L0[4,2]             1.111110e-01  1.111110e-01       NaN      NaN       NaN  \n",
       "L0[4,3]             4.444440e-01  4.444440e-01       NaN      NaN       NaN  \n",
       "S1[1,1]             5.000000e-01  5.000000e-01       NaN      NaN       NaN  \n",
       "S1[1,2]             8.310000e-14  8.310000e-14       NaN      NaN       NaN  \n",
       "S1[1,3]             8.310000e-14  8.310000e-14       NaN      NaN       NaN  \n",
       "S1[1,4]             5.000000e-01  5.000000e-01       NaN      NaN       NaN  \n",
       "S1[2,1]             5.215070e-06  5.215070e-06       NaN      NaN       NaN  \n",
       "S1[2,2]             0.000000e+00  0.000000e+00       NaN      NaN       NaN  \n",
       "S1[2,3]             9.999950e-01  9.999950e-01       NaN      NaN       NaN  \n",
       "S1[2,4]             0.000000e+00  0.000000e+00       NaN      NaN       NaN  \n",
       "S1[3,1]             0.000000e+00  0.000000e+00       NaN      NaN       NaN  \n",
       "S1[3,2]             9.999950e-01  9.999950e-01       NaN      NaN       NaN  \n",
       "S1[3,3]             0.000000e+00  0.000000e+00       NaN      NaN       NaN  \n",
       "S1[3,4]             5.215070e-06  5.215070e-06       NaN      NaN       NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit = rsa_model.sample(stan_data, show_console=True, chains=1, iter_warmup=0, adapt_engaged=False, iter_sampling=1)\n",
    "fit = rsa_model.sample(stan_data, show_console=True, chains=4, iter_warmup=500, adapt_engaged=True, iter_sampling=500)\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0:\n",
      "       big_blue  big_red  small_blue\n",
      "big        0.44     0.44        0.11\n",
      "small      0.17     0.17        0.67\n",
      "blue       0.17     0.67        0.17\n",
      "red        0.44     0.11        0.44\n",
      "S1:\n",
      "            big  small  blue  red\n",
      "big_blue   0.50   0.00  0.00 0.50\n",
      "big_red    0.00   0.00  1.00 0.00\n",
      "small_blue 0.00   1.00  0.00 0.00\n"
     ]
    }
   ],
   "source": [
    "L0_draws = fit.stan_variable('L0')\n",
    "S1_draws = fit.stan_variable('S1')\n",
    "\n",
    "L0 = L0_draws[0]\n",
    "S1 = S1_draws[0]\n",
    "\n",
    "df_L0 = pd.DataFrame(L0, index=utterances, columns=states)\n",
    "df_S1 = pd.DataFrame(S1, index=states, columns=utterances)\n",
    "\n",
    "print(\"L0:\")\n",
    "print(df_L0.to_string(float_format=\"{:.2f}\".format))\n",
    "print(\"S1:\")\n",
    "print(df_S1.to_string(float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Model evaluation by comparison to experiment data (42 points)\n",
    "3.3.1) Create a new file `sem_rsa.stan`. Adapt the vanilla RSA model in a way that allows you to infer all free parameters instead of specifying them beforehand. Condition the model on the observed production data (`data/data_exp1.csv`) and integrate over the free parameters. Preprocess the observed data in a way that you see fit for the modeling purpose. Assume uniform priors for each parameter. Use the generated quantities block in your Stan model to generate the posterior predictive distribution (read up [Stan documentation](https://mc-stan.org/docs/stan-users-guide/posterior-prediction.html) for this). Choose an appropriate number of iterations for warm up and sampling from the posterior. (16 points)\n",
    "3.3.2) Diagnose the model convergence and take actions if necessary. (4 points)\n",
    "3.3.3) Interpret a summary of the fitted model. (6 points)\n",
    "3.3.4) Correlate the model's posterior predictive distribution for overinformative utterance probabilities with the empirical data to assess and interpret model fit to the data. (8 points)\n",
    "3.3.5) Bonus: Introduce separate cost parameters for size and color. (6 bonus points)\n",
    "3.3.6) Interpret and discuss your findings. (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X) Reflection (no points, but mandatory)\n",
    "\n",
    "Reflect on your group work. What went well? What did not go well?\n",
    "\n",
    "Please note down the group members' team roles anonymously and reflect on how you filled this role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (studyproject)",
   "language": "python",
   "name": "studyproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
