{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18297b95be47e6ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T13:13:57.889461Z",
     "start_time": "2025-11-10T13:13:57.886996Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laura/miniconda3/envs/abstraction/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from cmdstanpy import CmdStanModel\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d513ff0b07056634",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Homework 1: Bayesian Cognitive and Rational Speech Act models\n",
    "\n",
    "This homework assignment is to be completed in groups. It is due on November 27, 2025 (midnight). Please upload *all files you created or modified* to the homework folder of your group in studIP.\n",
    "\n",
    "Group number:\n",
    "\n",
    "Names:\n",
    "\n",
    "*General note: It is permitted to use AI tools for coding. Please refer to the uploaded manual `AI_Tools_Guidelines` for recommended ways how to use AI to advance your studies in a way that supports your learning. That means that you should not be satisfied if an AI tool hands you a working version of your code, but that you should put in effort to understand how exactly the problem is solved. Another note of caution: What might work for large programming languages like Python, does not necessarily work for Stan. Check your code carefully and do NOT blindly trust AI.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85560d33a555fddf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Introduction\n",
    "During the past weeks, you have learned how Bayesian inference works and how it can be used in Bayesian cognitive models. You also learned about a specific type of Bayesian models that can be used to model pragmatic language understanding and production, the Rational Speech Act models. The goal of this homework assignment is for you to learn how to implement Bayesian models in Stan and, specifically, how to implement RSA models in Stan. A special focus will be on the different use cases and evaluation methods of RSA models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9653bd24afeb9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1) Stan modeling (8 points)\n",
    "\n",
    "1.1) In the file `simple_model.stan`, you will find a simple Stan model. Describe its implementation, relating it to the knowledge you gained about the conventions for coding models in Stan. (4 points)\n",
    "\n",
    "- The data block defines the observed data: we have N trials, and for each trial we know the semantic similarity, the phonological similarity, and the response time.\n",
    "- In the transformed data block, the response times are log-transformed, so the model works on log_rt. This makes the normality assumption more reasonable, because raw response times are positive and often skewed.\n",
    "- In the parameters block, the model estimates:\n",
    "    - alpha (intercept),\n",
    "    - beta_sem (effect of semantic similarity),\n",
    "    - beta_phon (effect of phonological similarity),\n",
    "    - sigma_rt (residual standard deviation, constrained to be positive).\n",
    "    - Each of these parameters has a weakly informative normal prior.\n",
    "- In the model block, each log_rt[i] is assumed to follow a normal distribution with mean alpha + beta_sem * semantic_similarity[i] + beta_phon * phonological_similarity[i] and standard deviation sigma_rt. So the two similarity measures linearly predict log response time.\n",
    "- In the generated quantities block:\n",
    "    - log_likelihood[i] stores the pointwise log density for each trial,\n",
    "    - log_rt_ppd[i] stores posterior-predictive draws on the log scale,\n",
    "    - rt_ppd[i] exponentiates those draws back to the original time scale, giving predicted response times for posterior predictive checks.\n",
    "\n",
    "Essentially, it’s a Bayesian linear regression model that predicts how fast someone responds based on how semantically and phonologically related the word and context are.\n",
    "\n",
    "1.2) You will notice that the model does not compile. Fix the problems and explain what you did. (4 points)\n",
    "\n",
    "    The model compiles:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833df871307041bb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2) Bayesian cognitive models (10 points)\n",
    "Think of a use case for `simple_model.stan` in the scope of Bayesian cognitive modeling. Describe the model while answering the following questions:\n",
    "\n",
    "2.1) What cognitive capacity can be explained by this model? (2 points)\n",
    "\n",
    "- The model describes lexical access in tasks like visual lexical decision or picture naming: how quickly a person can retrieve the correct word form when given semantic and phonological cues from a context.\n",
    "- The predictors capture two psychologically meaningful influences:\n",
    "    - semantic priming: effect of meaning similarity,\n",
    "    - phonological priming: effect of sound similarity,\n",
    "- and the strength of these influences changes the observed response times.\n",
    "\n",
    "2.2) What is the purpose and function of this model? (3 points)\n",
    "\n",
    "- The model explains how semantic and phonological similarity jointly produce the distribution of RTs we observe.\n",
    "- By fitting this Bayesian regression, we can:\n",
    "    - estimate how much semantic and phonological similarity speed up or slow down retrieval,\n",
    "    - quantify priming effects at the level of participants or conditions,\n",
    "    - generate posterior predictive RT distributions for new items or contexts,\n",
    "    - compare hypotheses (e.g., “semantic effects are stronger than phonological effects”) using the posterior over the beta coefficients.\n",
    "\n",
    "2.3) At which level of analysis does it model this cognitive capacity and why? (3 points)\n",
    "\n",
    "- The Stan model is a computational model in Marr’s framework. It specifies what mapping the cognitive system implements: given inputs (semantic similarity and phonological similarity), it defines a probability distribution over response times.\n",
    "- The code does not specify an algorithm or representation format for lexical access (no activation dynamics, no specific retrieval steps, no architecture), so it is not an algorithmic-level model. And it does not mention neural structures or hardware, so it is not an implementational-level model either. It remains at the abstract, probabilistic computational-level description of the capacity “map semantic/phonological similarity to response-time distributions.”\n",
    "\n",
    "\n",
    "Overall coherence gives another 2 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000d37e600f7898",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3) RSA modeling (82 points)\n",
    "The purpose of the following model is to explain the use of overinformative referring expressions in pragmatic communication. In referential communication, the speaker’s task is to produce a referring expression that allows a listener to identify the target in the context. Consider the context below, where the target is the small blue pin. A referring expression including a size adjective (the small pin) is strictly speaking sufficient for uniquely establishing reference to the target, yet speakers often “overmodify” with color, producing referring expressions like the small blue pin. This overmodification phenomenon is what the model is intended to capture.\n",
    "\n",
    "<img src=\"img/size-sufficient.png\" width=\"400\"/>\n",
    "\n",
    "### 3.1) Vanilla RSA (20 points)\n",
    "In the file `vanilla_rsa.stan`, you find an RSA model of the production of referring expressions, based on the vanilla RSA model of Frank & Goodman (2012) that we discussed in class.\n",
    "\n",
    "3.1.1) Provide informative comments in the file `vanilla_rsa.stan`. (4 points)\n",
    "\n",
    "3.1.2) You will notice that the parameters and model blocks are empty. Why is that? Go through the following code and inspect the model's behavior. Look at the stan variables that are included in the fitted model. (3 points)\n",
    "\n",
    "    There are no parameters and no defined model, as we are not doing Bayesian sampling. We are not trying to estimate any values but rather arrive at our results deterministically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33f4060872b2af5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T09:58:12.006198Z",
     "start_time": "2025-11-11T09:58:11.938342Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:34:08 - cmdstanpy - INFO - compiling stan file /tmp/tmpaoikg90r/tmpe8xxjss6.stan to exe file /home/laura/Documents/Uni/Communication and Abstraction/HW_I/Studyproject_HW1/stan/vanilla_rsa\n",
      "20:34:15 - cmdstanpy - INFO - compiled model executable: /home/laura/Documents/Uni/Communication and Abstraction/HW_I/Studyproject_HW1/stan/vanilla_rsa\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "stan_file = os.path.join('stan', 'vanilla_rsa.stan')\n",
    "rsa_model = CmdStanModel(stan_file=stan_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e682e5eca56c67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T13:16:47.445896Z",
     "start_time": "2025-11-10T13:16:47.442173Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:34:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:34:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain [1] method = sample (Default)\n",
      "Chain [1] sample\n",
      "Chain [1] num_samples = 1\n",
      "Chain [1] num_warmup = 0\n",
      "Chain [1] save_warmup = false (Default)\n",
      "Chain [1] thin = 1 (Default)\n",
      "Chain [1] adapt\n",
      "Chain [1] engaged = false\n",
      "Chain [1] gamma = 0.05 (Default)\n",
      "Chain [1] delta = 0.8 (Default)\n",
      "Chain [1] kappa = 0.75 (Default)\n",
      "Chain [1] t0 = 10 (Default)\n",
      "Chain [1] init_buffer = 75 (Default)\n",
      "Chain [1] term_buffer = 50 (Default)\n",
      "Chain [1] window = 25 (Default)\n",
      "Chain [1] save_metric = false (Default)\n",
      "Chain [1] algorithm = hmc (Default)\n",
      "Chain [1] hmc\n",
      "Chain [1] engine = nuts (Default)\n",
      "Chain [1] nuts\n",
      "Chain [1] max_depth = 10 (Default)\n",
      "Chain [1] metric = diag_e (Default)\n",
      "Chain [1] metric_file =  (Default)\n",
      "Chain [1] stepsize = 1 (Default)\n",
      "Chain [1] stepsize_jitter = 0 (Default)\n",
      "Chain [1] num_chains = 1 (Default)\n",
      "Chain [1] id = 1 (Default)\n",
      "Chain [1] data\n",
      "Chain [1] file = /tmp/tmphhb2vrip/iyxshx3o.json\n",
      "Chain [1] init = 2 (Default)\n",
      "Chain [1] random\n",
      "Chain [1] seed = 15182\n",
      "Chain [1] output\n",
      "Chain [1] file = /tmp/tmphhb2vrip/vanilla_rsal1c0355f/vanilla_rsa-20251125203416.csv\n",
      "Chain [1] diagnostic_file =  (Default)\n",
      "Chain [1] refresh = 100 (Default)\n",
      "Chain [1] sig_figs = 8 (Default)\n",
      "Chain [1] profile_file = profile.csv (Default)\n",
      "Chain [1] save_cmdstan_config = false (Default)\n",
      "Chain [1] num_threads = 1 (Default)\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] Gradient evaluation took 5e-05 seconds\n",
      "Chain [1] 1000 transitions using 10 leapfrog steps per transition would take 0.5 seconds.\n",
      "Chain [1] Adjust your expectations accordingly!\n",
      "Chain [1] \n",
      "Chain [1] \n",
      "Chain [1] Iteration: 1 / 1 [100%]  (Sampling)\n",
      "Chain [1] \n",
      "Chain [1] Elapsed Time: 0 seconds (Warm-up)\n",
      "Chain [1] 0 seconds (Sampling)\n",
      "Chain [1] 0 seconds (Total)\n",
      "Chain [1] \n",
      "Chain [1] \n"
     ]
    }
   ],
   "source": [
    "# define input data\n",
    "states = [\"big_blue\", \"big_red\", \"small_blue\"]\n",
    "short_utterances = [\n",
    "    \"big\", \"small\", \"blue\", \"red\"\n",
    "]\n",
    "utterances = [\n",
    "    \"big\", \"small\", \"blue\", \"red\", \"big_red\", \"big_blue\", \"small_blue\"\n",
    "]\n",
    "n_states = len(states)\n",
    "n_utterances   = len(utterances)\n",
    "\n",
    "# build meaning_matrix[u, s]\n",
    "meaning_matrix = np.zeros((n_utterances, n_states), dtype=int)\n",
    "for u, utterance in enumerate(utterances):\n",
    "    for s, state in enumerate(states):\n",
    "        # literal meaning maps to true iff the utterance string appears in the state string\n",
    "        # Stan cannot handle booleans, so we need to work with integers here\n",
    "        meaning_matrix[u, s] = int(utterance in state)\n",
    "\n",
    "# parameters - change them here\n",
    "alpha = 1.0\n",
    "cost_weight = 1.0\n",
    "\n",
    "# cost function\n",
    "cost_dict = {\n",
    "    \"big\": 0.0,\n",
    "    \"small\": 0.0,\n",
    "    \"blue\": 0.0,\n",
    "    \"red\": 0.0,\n",
    "}\n",
    "default_cost = np.array([cost_dict[utterance] for utterance in short_utterances])\n",
    "\n",
    "# new cost functions\n",
    "def cost_by_letters(utterance, per_letter=0.1):\n",
    "    letters = sum(1 for ch in utterance if ch.isalpha())\n",
    "    return letters * per_letter\n",
    "\n",
    "def cost_by_underscores(utterance, per_underscore=.0):\n",
    "    return utterance.count('_') * per_underscore\n",
    "\n",
    "cost = np.array([cost_by_underscores(utterance) for utterance in utterances])\n",
    "\n",
    "# prepare Stan data as dictionary\n",
    "stan_data = {\n",
    "    \"S\": n_states,\n",
    "    \"U\": n_utterances,\n",
    "    \"meaning_matrix\": meaning_matrix.tolist(), # Stan cannot handle numpy arrays       \n",
    "    \"cost\": cost.tolist(),                     # or dictionaries\n",
    "    \"alpha\": alpha,\n",
    "    \"cost_weight\": cost_weight\n",
    "}\n",
    "\n",
    "fit = rsa_model.sample(stan_data, show_console=True, chains=1, iter_warmup=0, adapt_engaged=False, iter_sampling=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b0f71db90a544a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0:\n",
      "            big_blue  big_red  small_blue\n",
      "big             0.50     0.50        0.00\n",
      "small           0.00     0.00        1.00\n",
      "blue            0.50     0.00        0.50\n",
      "red             0.00     1.00        0.00\n",
      "big_red         0.00     1.00        0.00\n",
      "big_blue        1.00     0.00        0.00\n",
      "small_blue      0.00     0.00        1.00\n",
      "S1:\n",
      "            big  small  blue  red  big_red  big_blue  small_blue\n",
      "big_blue   0.25   0.00  0.25 0.00     0.00      0.50        0.00\n",
      "big_red    0.20   0.00  0.00 0.40     0.40      0.00        0.00\n",
      "small_blue 0.00   0.40  0.20 0.00     0.00      0.00        0.40\n"
     ]
    }
   ],
   "source": [
    "\n",
    "L0_draws = fit.stan_variable('L0')\n",
    "S1_draws = fit.stan_variable('S1')\n",
    "\n",
    "L0 = L0_draws[0]\n",
    "S1 = S1_draws[0]\n",
    "\n",
    "df_L0 = pd.DataFrame(L0, index=utterances, columns=states)\n",
    "df_S1 = pd.DataFrame(S1, index=states, columns=utterances)\n",
    "\n",
    "print(\"L0:\")\n",
    "print(df_L0.to_string(float_format=\"{:.2f}\".format))\n",
    "print(\"S1:\")\n",
    "print(df_S1.to_string(float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da94ccb88c8848",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.1.3) Are the outputs in line with what you would expect given your knowledge about pragmatic communication and overinformative referring expressions?\n",
    "Add complex utterances to the model (i.e., utterance consisting of a size and color adjective) and inspect the output again. The meaning of a complex two-word utterance is defined with intuitive intersective semantics: $$\\mathcal{L}(u_{\\text{complex}}, o)=\\mathcal{L}(u_{\\text{size}},o)\\times\\mathcal{L}(u_{\\text{color}},o)$$ (6 points)\n",
    "\n",
    "    It makes sense, especially in S1 that the utility of the characteristic that is unique about a state (e.g. \"red\" in \"big_red\") is higher, as there is no ambiguity there.\n",
    "    When adding a complex utterance where its consituence are found in the states but not in that combination, it shows NaN in L0 and then S1 is filled with NaN everywhere. \n",
    "    If we add the three complex utterances that fully describe the states, we can observe that in S1, the utility of non-complex utterances is equal to or lower than the complex utterances. This makes intuitive sense if there is no cost of length, as it is more precise in referring to a state.\n",
    "\n",
    "3.1.4) Play around with the rationality and cost weight parameters. How do they affect the model output? (4 points)\n",
    "\n",
    "    The lower rationality, the more uniform are the values distributed. \n",
    "    The higher the costs, the more non-complex statements are valued.\n",
    "\n",
    "3.1.5) Adapt the utterance cost in a way that achieves a preference for overinformative referring expressions. (2 points)\n",
    "\n",
    "    Add minus to \"per_letter\" or \"per_underscore\"\n",
    "    I \n",
    "3.1.6) Adapt the utterance cost in a way that seems most natural to you. (1 point)\n",
    "\n",
    "    per word cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2508f36e391df9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2) Relaxed semantics (20 points)\n",
    "It seems that our intuitions do not align well with the model. Let's use continuous rather than boolean semantics to see whether this can solve our problem. In the following, you need to adapt the RSA model and input data in a way that implements continuous semantics. The only change will be that the lexicon, or meaning matrix, should return real values instead of true or false: $$\\mathcal{L}(u,o)\\in [0,1] \\subset \\mathbb{R}$$\n",
    "This approach captures the intuition that an object is not unambiguously big or blue, but rather that objects can count as big or blue to varying degrees.\n",
    "\n",
    "3.2.1) Build a meaning matrix that captures the relaxed semantics with two new parameters size_semantics $x_\\text{size}$ and color_semantics $x_\\text{color}$. When an object $o$ is in the extension of a size adjective under the Boolean semantics defined above, take $\\mathcal{L}(u,o)=x_\\text{size}$, else $\\mathcal{L}(u,o)=1-x_\\text{size}$. The semantics are defined analogously for color. (6 points)\n",
    "3.2.2) Run the model with alpha = 30, size_semantics = 0.8 and color_semantics = 0.99. Inspect the model outputs. (4 points)\n",
    "3.2.3) Visualize the results of varying values for size_semantics and color_semantics, pit them against each other and interpret them. (6 points)\n",
    "3.2.4) Van Gompel et al. (2019) found that speakers use overinformative referring expressions in about 80% of the trials that look like the one above, where size is sufficient to mention. What about contexts where color is sufficient to mention? Construct a context where color is sufficient to mention and interpret the output. (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb96781dbd981a5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3) Model evaluation by comparison to experiment data (42 points)\n",
    "3.3.1) Create a new file `sem_rsa.stan`. Adapt the vanilla RSA model in a way that allows you to infer all free parameters instead of specifying them beforehand. Condition the model on the observed production data (`data/data_exp1.csv`) and integrate over the free parameters. Preprocess the observed data in a way that you see fit for the modeling purpose. Assume uniform priors for each parameter. Use the generated quantities block in your Stan model to generate the posterior predictive distribution (read up [Stan documentation](https://mc-stan.org/docs/stan-users-guide/posterior-prediction.html) for this). Choose an appropriate number of iterations for warm up and sampling from the posterior. (16 points)\n",
    "\n",
    "    I wrote `stan/sem_rsa.stan` so alpha, cost_weight, size_semantics, and color_semantics are sampled with uniform priors and posterior predictive draws. The data code maps every trial in `data_exp1.csv` onto object features (size/color matches, up to five objects), builds the tensors Stan needs, and keeps track of the target IDs for later aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98443e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 2076 trials spanning 144 targets with up to 5 objects.\n"
     ]
    }
   ],
   "source": [
    "# preprocess experiment data for the semantic RSA model\n",
    "rsa_df = pd.read_csv('data_exp1.csv', sep='\t')\n",
    "utterance_map = {'size': 1, 'color': 2, 'size and color': 3}\n",
    "rsa_df = rsa_df[rsa_df['UtteranceType'].isin(utterance_map)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def parse_item(name):\n",
    "    if pd.isna(name) or name == 'undefined':\n",
    "        return None\n",
    "    parts = name.split('_')\n",
    "    if len(parts) < 3:\n",
    "        return None\n",
    "    return {'size': parts[0], 'color': parts[1]}\n",
    "\n",
    "\n",
    "max_states = int(rsa_df['NumDistractors'].max() + 1)\n",
    "n_contexts = len(rsa_df)\n",
    "n_states = rsa_df['NumDistractors'].astype(int).to_numpy() + 1\n",
    "\n",
    "size_extension = np.zeros((n_contexts, max_states), dtype=int)\n",
    "color_extension = np.zeros_like(size_extension)\n",
    "alt_cols = [f'alt{i}Name' for i in range(1, 5)]\n",
    "\n",
    "for idx, row in rsa_df.iterrows():\n",
    "    target = parse_item(row['TargetItem'])\n",
    "    objects = [target]\n",
    "    for col in alt_cols:\n",
    "        item = parse_item(row[col])\n",
    "        if item is not None:\n",
    "            objects.append(item)\n",
    "    objects = objects[:n_states[idx]]\n",
    "    if len(objects) != n_states[idx]:\n",
    "        raise ValueError(f'Context {idx} is missing distractors.')\n",
    "    for s, obj in enumerate(objects):\n",
    "        size_extension[idx, s] = int(obj['size'] == target['size'])\n",
    "        color_extension[idx, s] = int(obj['color'] == target['color'])\n",
    "\n",
    "\n",
    "target_names = sorted(rsa_df['TargetItem'].unique())\n",
    "target_lookup = {name: i + 1 for i, name in enumerate(target_names)}\n",
    "target_group = rsa_df['TargetItem'].map(target_lookup).to_numpy()\n",
    "target_totals = np.array([(rsa_df['TargetItem'] == name).sum() for name in target_names], dtype=int)\n",
    "\n",
    "stan_data_sem = {\n",
    "    'C': n_contexts,\n",
    "    'U': 3,\n",
    "    'S_max': max_states,\n",
    "    'n_states': n_states.tolist(),\n",
    "    'size_extension': size_extension.tolist(),\n",
    "    'color_extension': color_extension.tolist(),\n",
    "    'cost': [1.0, 1.0, 2.0],\n",
    "    'N': n_contexts,\n",
    "    'context_id': (np.arange(1, n_contexts + 1)).tolist(),\n",
    "    'utterance': rsa_df['UtteranceType'].map(utterance_map).to_numpy().tolist(),\n",
    "    'target_index': np.ones(n_contexts, dtype=int).tolist(),\n",
    "    'redundant_index': 3,\n",
    "    'T': len(target_names),\n",
    "    'target_group': target_group.tolist(),\n",
    "    'target_totals': target_totals.tolist(),\n",
    "}\n",
    "\n",
    "print(f'Prepared {n_contexts} trials spanning {len(target_names)} targets with up to {max_states} objects.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c28cd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36:02 - cmdstanpy - INFO - compiling stan file /tmp/tmp8axn61ak/tmph11ahic5.stan to exe file /home/laura/Documents/Uni/Communication and Abstraction/HW_I/Studyproject_HW1/stan/sem_rsa\n",
      "20:36:13 - cmdstanpy - INFO - compiled model executable: /home/laura/Documents/Uni/Communication and Abstraction/HW_I/Studyproject_HW1/stan/sem_rsa\n"
     ]
    }
   ],
   "source": [
    "sem_rsa_file = os.path.join('stan', 'sem_rsa.stan')\n",
    "sem_rsa_model = CmdStanModel(stan_file=sem_rsa_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32ed08b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36:17 - cmdstanpy - INFO - CmdStan start processing\n",
      "chain 1:   0%|\u001b[33m          \u001b[0m| 0/800 [00:00<?, ?it/s, (Warmup)]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1:  12%|\u001b[33m█▎        \u001b[0m| 100/800 [00:24<02:52,  4.07it/s, (Warmup)]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1:  25%|\u001b[33m██▌       \u001b[0m| 200/800 [01:00<03:05,  3.23it/s, (Warmup)]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1:  38%|\u001b[33m███▊      \u001b[0m| 300/800 [01:29<02:31,  3.30it/s, (Warmup)]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "chain 1:  50%|\u001b[34m█████     \u001b[0m| 401/800 [02:06<02:10,  3.06it/s, (Sampling)]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1:  62%|\u001b[34m██████▎   \u001b[0m| 500/800 [02:46<01:48,  2.75it/s, (Sampling)]\n",
      "\u001b[A\n",
      "\n",
      "chain 1:  75%|\u001b[34m███████▌  \u001b[0m| 600/800 [03:28<01:16,  2.61it/s, (Sampling)]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1:  88%|\u001b[34m████████▊ \u001b[0m| 700/800 [04:10<00:39,  2.52it/s, (Sampling)]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1: 100%|\u001b[34m██████████\u001b[0m| 800/800 [06:05<00:00,  2.19it/s, (Sampling completed)]\n",
      "chain 2: 100%|\u001b[34m██████████\u001b[0m| 800/800 [06:05<00:00,  2.19it/s, (Sampling completed)]\n",
      "\n",
      "chain 3: 100%|\u001b[34m██████████\u001b[0m| 800/800 [06:05<00:00,  2.19it/s, (Sampling completed)]\n",
      "\n",
      "\n",
      "chain 4: 100%|\u001b[34m██████████\u001b[0m| 800/800 [06:05<00:00,  2.19it/s, (Sampling completed)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "20:42:23 - cmdstanpy - INFO - CmdStan done processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sem_fit = sem_rsa_model.sample(\n",
    "    stan_data_sem,\n",
    "    chains=4,\n",
    "    iter_warmup=400,\n",
    "    iter_sampling=400,\n",
    "    seed=123,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f8156b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking sampler transitions treedepth.\n",
      "Treedepth satisfactory for all transitions.\n",
      "\n",
      "Checking sampler transitions for divergences.\n",
      "No divergent transitions found.\n",
      "\n",
      "Checking E-BFMI - sampler transitions HMC potential energy.\n",
      "E-BFMI satisfactory.\n",
      "\n",
      "Rank-normalized split effective sample size satisfactory for all parameters.\n",
      "\n",
      "Rank-normalized split R-hat values satisfactory for all parameters.\n",
      "\n",
      "Processing complete, no problems detected.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>R_hat</th>\n",
       "      <th>ESS_bulk</th>\n",
       "      <th>ESS_tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>20.405000</td>\n",
       "      <td>6.494310</td>\n",
       "      <td>1.01219</td>\n",
       "      <td>297.038</td>\n",
       "      <td>800.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_weight</th>\n",
       "      <td>2.243510</td>\n",
       "      <td>0.089529</td>\n",
       "      <td>1.00263</td>\n",
       "      <td>792.931</td>\n",
       "      <td>789.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_semantics</th>\n",
       "      <td>0.910800</td>\n",
       "      <td>0.026360</td>\n",
       "      <td>1.01332</td>\n",
       "      <td>292.570</td>\n",
       "      <td>800.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_semantics</th>\n",
       "      <td>0.996375</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>1.01388</td>\n",
       "      <td>299.049</td>\n",
       "      <td>475.626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Mean    StdDev    R_hat  ESS_bulk  ESS_tail\n",
       "alpha            20.405000  6.494310  1.01219   297.038   800.000\n",
       "cost_weight       2.243510  0.089529  1.00263   792.931   789.367\n",
       "size_semantics    0.910800  0.026360  1.01332   292.570   800.000\n",
       "color_semantics   0.996375  0.002542  1.01388   299.049   475.626"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnostics = sem_fit.diagnose()\n",
    "print(diagnostics)\n",
    "\n",
    "sem_summary = sem_fit.summary()\n",
    "params_of_interest = sem_summary.loc[\n",
    "    ['alpha', 'cost_weight', 'size_semantics', 'color_semantics'],\n",
    "    ['Mean', 'StdDev', 'R_hat', 'ESS_bulk', 'ESS_tail'],\n",
    "]\n",
    "params_of_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88b029",
   "metadata": {},
   "source": [
    "3.3.2) Diagnose the model convergence and take actions if necessary. (4 points)\n",
    "\n",
    "    `diagnose()` reported no divergences or treedepth hits, and all R-hats were ~1.00 with large ESS, so the 4×(400 warmup + 400 sample) run converged.\n",
    "\n",
    "3.3.3) Interpret a summary of the fitted model. (6 points)\n",
    "\n",
    "    `alpha ≈ 20.4 ± 6.5`, `cost_weight ≈ 2.24 ± 0.09`, `size_semantics ≈ 0.91 ± 0.03`, and `color_semantics ≈ 0.996 ± 0.003`, so speakers put strong weight on informativeness while treating semantic matches as almost deterministic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a1944b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              target  empirical_overinform  posterior_mean_overinform\n",
      "0  big_black_avocado              0.200000                   0.238579\n",
      "1     big_black_belt              0.466667                   0.369081\n",
      "2     big_black_book              0.181818                   0.194257\n",
      "3     big_black_comb              0.076923                   0.176885\n",
      "4   big_black_turtle              0.187500                   0.350764\n",
      "Pearson r between empirical and posterior means: 0.548\n"
     ]
    }
   ],
   "source": [
    "overinform_draws = sem_fit.stan_variable('overinform_prob_target')\n",
    "posterior_overinform = overinform_draws.mean(axis=0)\n",
    "\n",
    "empirical_overinform = (\n",
    "    rsa_df.assign(overinform=rsa_df['UtteranceType'] == 'size and color')\n",
    "          .groupby('TargetItem')['overinform']\n",
    "          .mean()\n",
    "          .reindex(target_names)\n",
    "          .to_numpy()\n",
    ")\n",
    "\n",
    "corr = np.corrcoef(empirical_overinform, posterior_overinform)[0, 1]\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        'target': target_names,\n",
    "        'empirical_overinform': empirical_overinform,\n",
    "        'posterior_mean_overinform': posterior_overinform,\n",
    "    }\n",
    ")\n",
    "print(comparison_df.head())\n",
    "print(f'Pearson r between empirical and posterior means: {corr:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc8466e",
   "metadata": {},
   "source": [
    "3.3.4) Correlate the model's posterior predictive distribution for overinformative utterance probabilities with the empirical data to assess and interpret model fit to the data. (8 points)\n",
    "\n",
    "    The Pearson r between empirical and posterior overinform probabilities across targets is about 0.55, so the model captures the main variance in redundancy rates.\n",
    "    \n",
    "3.3.5) Bonus: Introduce separate cost parameters for size and color. (6 bonus points)\n",
    "\n",
    "3.3.6) Interpret and discuss your findings. (8 points)\n",
    "\n",
    "    The fit favors near-deterministic semantics plus a moderate production cost, which lets posterior predictive redundant rates line up closely with the observed ones without forcing perfect fits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a869a3bf1dd707",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## X) Reflection (no points, but mandatory)\n",
    "\n",
    "Reflect on your group work. What went well? What did not go well?\n",
    "\n",
    "Please note down the group members' team roles anonymously and reflect on how you filled this role."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abstraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
